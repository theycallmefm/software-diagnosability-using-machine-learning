{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import feature_selection as fs\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "rcParams['figure.figsize'] = 15, 10\n",
    "import seaborn as sns\n",
    "import pylab\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import random\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "import statsmodels.formula.api as sm\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (20.0, 15.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPercentageRangesEqually(classCount,df):\n",
    "    percentages = df['percentage']\n",
    "    percentageArray=[]\n",
    "    rangeArray=[]\n",
    "    averageClassCount=len(percentages)/classCount\n",
    "    averageClassCount=round(averageClassCount)\n",
    "    \n",
    "    for i in range(0, len(percentages)):\n",
    "        percentageArray.append(percentages[i])\n",
    "    \n",
    "    \n",
    "    percentagesArray=np.sort(percentageArray)\n",
    "    \n",
    "    \n",
    "    for i in range(0, len(percentages)):\n",
    "        if(i%averageClassCount==0):\n",
    "            rangeArray.append(percentagesArray[i])\n",
    "    return rangeArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeClassDataFrame(df,classCount,command):\n",
    "    rangeArray=[]\n",
    "    if(command==\"betweenEqual\"):\n",
    "        rangeArray=findPercentageRangesEqually(classCount,df)\n",
    "    elif(command==\"equallySliced\"):\n",
    "        for i in range(classCount):\n",
    "            rangeArray.append(i*(1/classCount))\n",
    "    classArray=[]\n",
    "    ClassLibrary=\"ABCDEFGHIJKLMNOPRST\"\n",
    "    for i in range(df.shape[0]):\n",
    "        for j in range(classCount):\n",
    "            if(df['percentage'][i]>rangeArray[j]):\n",
    "                foundClass=ClassLibrary[j]\n",
    "        classArray.append(foundClass)\n",
    "    df['ClassLabel']=pd.Series(classArray)\n",
    "    df2=df.drop(columns=['percentage'])\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureSelection(df):\n",
    "    X = pd.DataFrame(df.iloc[:,:-1])\n",
    "    y = pd.DataFrame(df.iloc[:,-1])\n",
    "    y = pd.get_dummies(y)\n",
    "    model = ExtraTreesClassifier(random_state=1)\n",
    "    model.fit(X, y)\n",
    "    # display the relative importance of each attribute\n",
    "    features = list(X.columns)\n",
    "\n",
    "    y_pos = np.arange(len(features))\n",
    "\n",
    "    d={}\n",
    "    c=0\n",
    "    for i in features:\n",
    "        d[i]=model.feature_importances_[c]\n",
    "        c=c+1\n",
    "    newd = sorted(d.items(), key=lambda kv: kv[1])\n",
    "    dd={}\n",
    "    for i in range(0,len(features)):\n",
    "        dd[newd[i][0]]=newd[i][1]\n",
    "    plt.barh(range(len(dd)), list(dd.values()), align='center')\n",
    "    plt.yticks(range(len(dd)), list(dd.keys()))\n",
    "    plt.show()\n",
    "    print(dd)\n",
    "    return dd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureSelectionRegression(df):\n",
    "    import pandas as pd\n",
    "    X = pd.DataFrame(df.iloc[:,:-1])\n",
    "    y = pd.DataFrame(df.iloc[:,-1])\n",
    "    features = list(X.columns)\n",
    "    f_and_p_test=list()\n",
    "    f_test, p_test=fs.f_regression(X, y, center=True)\n",
    "    \n",
    "    fd={}\n",
    "    c=0\n",
    "    for i in features:\n",
    "        fd[i]=f_test[c]\n",
    "        c=c+1\n",
    "    newfd = sorted(fd.items(), key=lambda kv: kv[1])\n",
    "    fdd={}\n",
    "    for i in range(0,len(features)):\n",
    "        fdd[newfd[i][0]]=newfd[i][1]\n",
    "    plt.barh(range(len(fdd)), list(fdd.values()), align='center')\n",
    "    plt.yticks(range(len(fdd)), list(fdd.keys()))\n",
    "    plt.show()\n",
    "    \n",
    "    pd={}\n",
    "    t=0\n",
    "    for i in features:\n",
    "        pd[i]=f_test[t]\n",
    "        t=t+1\n",
    "    newpd = sorted(pd.items(), key=lambda kv: kv[1])\n",
    "    pdd={}\n",
    "    for j in range(0,len(features)):\n",
    "        pdd[newpd[j][0]]=newpd[j][1]\n",
    "    plt.barh(range(len(pdd)), list(pdd.values()), align='center')\n",
    "    plt.yticks(range(len(pdd)), list(pdd.keys()))\n",
    "    plt.show()\n",
    "    \n",
    "    return fdd,pdd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortFeatures(keyList,corrArray):\n",
    "    \n",
    "    sortedArray=[]\n",
    "    for i in corrArray:\n",
    "        sortedSubArray=[]\n",
    "        for j in len(i):\n",
    "            for t in keyList:\n",
    "                if(i[j]==t):\n",
    "                    sortedSubArrray.append(t)\n",
    "        sortedArray.append(sortedSubArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TreeMethod(methodName, estimator):\n",
    "    #you can add other tree classifiers\n",
    "    if(methodName==\"AdaBoost\"):\n",
    "        clf=AdaBoostClassifier(n_estimators=estimator)\n",
    "    elif(methodName==\"ExtraTrees\"):\n",
    "        clf=ExtraTreesClassifier(n_estimators=estimator, criterion=\"gini\", max_depth=None, bootstrap=True)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def TreeClassifier(classCount,csvName,command,methodName):\n",
    "    file = open(csvName+'_'+methodName+'_'+command+'_C_'+str(classCount)+'.txt')\n",
    "    df2 = pd.read_csv(csvName)\n",
    "    df2 = df2.dropna()\n",
    "    df2=df2.reset_index(drop=True)\n",
    "    df=makeClassDataFrame(df2,classCount,command)\n",
    "    dd=FeatureSelection(df)\n",
    "    keyList=list(dd.keys())\n",
    "    lines_of_text=[]\n",
    "    print(\"ClassCount=\"+str(classCount)+\"\\n\")\n",
    "    lines_of_text.append(\"ClassCount=\"+str(classCount)+\"\\n\")\n",
    "    featuresLen = len(list(df2.columns))-3\n",
    "    for i in range(0,featuresLen):\n",
    "        droppedColumn=keyList[i]\n",
    "        df=df.drop(columns=[str(droppedColumn)])\n",
    "        X = pd.DataFrame(df.iloc[:,:-1])\n",
    "        X = (X - X.mean()) / (X.max() - X.min())\n",
    "        y = pd.DataFrame(df.iloc[:,-1])\n",
    "        y = pd.get_dummies(y)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "        ### convert one hot to numbers\n",
    "        y_train = np.argmax(y_train.values, axis=-1)\n",
    "\n",
    "        y_true = np.argmax(y_test.values, axis=-1)\n",
    "        maxAccuracy=0\n",
    "        lineString=\"\"\n",
    "        for j in range(1,51):#change range\n",
    "            estimator=j*100\n",
    "            clf = TreeMethod(methodName,estimator)\n",
    "            clf.fit(X_train.values, y_train)\n",
    "            y_pred = clf.predict(X_test.values)\n",
    "            accuracy=accuracy_score(y_true, y_pred)\n",
    "            if(accuracy>maxAccuracy):\n",
    "                maxAccuracy=accuracy\n",
    "                lineString=\"DroppedColumn:\"+droppedColumn+\" Estimator:\" +str(estimator)+\" Accuracy:\"+str(accuracy)+\"\\n\"\n",
    "                \n",
    "        print(lineString)\n",
    "        file.write(lineString)\n",
    "        print(\"ClassCount:\"+ str(classCount)+ \" Finished:\"+droppedColumn)\n",
    "\n",
    "    file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(classCount,csvName,command):\n",
    "    file = open(csvName+'_SVM_'+command+'_C_'+str(classCount)+'.txt','w')\n",
    "    df2 = pd.read_csv(csvName)\n",
    "    df2 = df2.dropna()\n",
    "    df2=df2.reset_index(drop=True)\n",
    "    df=makeClassDataFrame(df2,classCount,command)\n",
    "    dd=FeatureSelection(df)\n",
    "    keyList=list(dd.keys())\n",
    "    lines_of_text=[]\n",
    "    print(\"ClassCount=\"+str(classCount)+\"\\n\")\n",
    "    lines_of_text.append(\"ClassCount=\"+str(classCount)+\"\\n\")\n",
    "    featuresLen = len(list(df2.columns))-3\n",
    "    for i in range(0,featuresLen):\n",
    "        droppedColumn=keyList[i]\n",
    "        df=df.drop(columns=[str(droppedColumn)])\n",
    "        X = pd.DataFrame(df.iloc[:,:-1])\n",
    "        X = (X - X.mean()) / (X.max() - X.min())\n",
    "        y = pd.DataFrame(df.iloc[:,-1])\n",
    "        y = pd.get_dummies(y)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "        ### convert one hot to numbers\n",
    "        y_train = np.argmax(y_train.values, axis=-1)\n",
    "\n",
    "        y_true = np.argmax(y_test.values, axis=-1)\n",
    "        maxAccuracy=0\n",
    "        lineString=\"\"\n",
    "        for j in range(1,51):#change range\n",
    "            Cnew=j*0.01\n",
    "            clf = SVC(C = Cnew, kernel='rbf', degree=3, )\n",
    "            clf.fit(X_train.values, y_train)\n",
    "\n",
    "            y_pred = clf.predict(X_test.values)\n",
    "\n",
    "            accuracy=accuracy_score(y_true, y_pred)\n",
    "            \n",
    "            if(accuracy>maxAccuracy):\n",
    "                maxAccuracy=accuracy\n",
    "                lineString=\"DroppedColumn:\"+droppedColumn+\" C:\" +str(Cnew)+\" Accuracy:\"+str(accuracy)+\"\\n\"\n",
    "                \n",
    "        print(lineString)\n",
    "        file.write(lineString)\n",
    "        print(\"ClassCount:\"+ str(classCount)+ \" Finished:\"+droppedColumn)\n",
    "\n",
    "    file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGDRegressor(csvName):\n",
    "    file = open('SGDRegressorTest'+'.txt','w')\n",
    "    df = pd.read_csv(csvName)\n",
    "    df = df.dropna()\n",
    "    df=df.reset_index(drop=True)\n",
    "    fdd,pdd=FeatureSelectionRegression(df)\n",
    "    keyList=list(fdd.keys())\n",
    "    lines_of_text=[]\n",
    "    print(\"F Test Commencing\\n\")\n",
    "    featuresLen = len(list(df.columns))-2\n",
    "    for i in range(0,featuresLen):\n",
    "        droppedColumn=keyList[i]\n",
    "        df=df.drop(columns=[str(droppedColumn)])\n",
    "        X = pd.DataFrame(df.iloc[:,:-1])\n",
    "        X = (X - X.mean()) / (X.max() - X.min())\n",
    "        y = pd.DataFrame(df.iloc[:,-1])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "        ### convert one hot to numbers\n",
    "        y_true=y_test\n",
    "        maxAccuracy=0\n",
    "        lineString=\"\"\n",
    "        for j in range(1,51):#change range\n",
    "            estimator=j*100\n",
    "            clf = linear_model.SGDRegressor()\n",
    "            clf.fit(X_train.values, y_train)\n",
    "            y_pred = clf.predict(X_test.values)\n",
    "            accuracy=metrics.r2_score(y_true, y_pred)\n",
    "            \n",
    "            if(accuracy>maxAccuracy):\n",
    "                maxAccuracy=accuracy\n",
    "                lineString=\"DroppedColumn:\"+droppedColumn+\" Test:F MSE:\"+str(accuracy)+\"\\n\"\n",
    "                \n",
    "        print(lineString)\n",
    "        file.write(lineString)\n",
    "    df = pd.read_csv(csvName)\n",
    "    df = df.dropna()\n",
    "    keyList=list(pdd.keys())\n",
    "    lines_of_text=[]\n",
    "    print(\"P Test Commencing\\n\")\n",
    "    for i in range(0,featuresLen):\n",
    "        droppedColumn=keyList[i]\n",
    "        df=df.drop(columns=[str(droppedColumn)])\n",
    "        X = pd.DataFrame(df.iloc[:,:-1])\n",
    "        X = (X - X.mean()) / (X.max() - X.min())\n",
    "        y = pd.DataFrame(df.iloc[:,-1])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "        ### convert one hot to numbers\n",
    "        y_true=y_test\n",
    "        maxAccuracy=0\n",
    "        lineString=\"\"\n",
    "        for j in range(1,51):#change range\n",
    "            estimator=j*100\n",
    "            clf = linear_model.SGDRegressor()\n",
    "            clf.fit(X_train.values, y_train)\n",
    "            y_pred = clf.predict(X_test.values)\n",
    "            accuracy=metrics.r2_score(y_true, y_pred)\n",
    "            \n",
    "            if(accuracy>maxAccuracy):\n",
    "                maxAccuracy=accuracy\n",
    "                lineString=\"DroppedColumn:\"+droppedColumn+\" Test:P MSE:\"+str(accuracy)+\"\\n\"\n",
    "                \n",
    "        print(lineString)\n",
    "        file.write(lineString)\n",
    "\n",
    "    file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Elastic(csvName):\n",
    "    file = open('ElasticTest'+csvName[4:]+'.txt','w+')\n",
    "    df = pd.read_csv(csvName)\n",
    "    df=df.dropna()\n",
    "    df=df.reset_index(drop=True)\n",
    "    fdd,pdd=FeatureSelectionRegression(df)\n",
    "    keyList=list(fdd.keys())\n",
    "    lines_of_text=[]\n",
    "    print(\"F Test Commencing\\n\")\n",
    "    featuresLen = len(list(df.columns))-2\n",
    "    for i in range(0,featuresLen):\n",
    "        droppedColumn=keyList[i]\n",
    "        df=df.drop(columns=[str(droppedColumn)])\n",
    "        X = pd.DataFrame(df2.iloc[:,:-1])\n",
    "        X = (X - X.mean()) / (X.max() - X.min())\n",
    "        y = pd.DataFrame(df2.iloc[:,-1])\n",
    "        \n",
    "        sc_x = StandardScaler()\n",
    "        sc_y = StandardScaler()\n",
    "        # Scale x and y (two scale objects)\n",
    "        X = sc_x.fit_transform(X)\n",
    "        y = sc_y.fit_transform(y)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "        ### convert one hot to numbers\n",
    "        y_true=y_test\n",
    "        maxAccuracy=1\n",
    "        lineString=\"\"\n",
    "        for j in range(1,100):#change range\n",
    "            for t in range(1,100):\n",
    "                alpha1=j*0.001\n",
    "                l1=t*0.01\n",
    "                clf =linear_model.ElasticNet(alpha=alpha1, l1_ratio=l1, max_iter=10000, positive=False, precompute=False, random_state=0, selection='cyclic', tol=0.0001, warm_start=False)\n",
    "                clf.fit(X_train, y_train)\n",
    "                y_pred = clf.predict(X_test)\n",
    "                accuracy=metrics.r2_score(y_true, y_pred)\n",
    "                if(accuracy<maxAccuracy):\n",
    "                    maxAccuracy=accuracy\n",
    "                    lineString=\"DroppedColumn:\"+droppedColumn+\" Alpha:\"+str(alpha1)+\" L1 ratio:\"+str(l1) +\" Test:F MSE:\"+str(accuracy)+\"\\n\"\n",
    "                \n",
    "        print(lineString)\n",
    "        file.write(lineString)\n",
    "    df = pd.read_csv(csvName)\n",
    "    df = df.dropna()\n",
    "    keyList=list(pdd.keys())\n",
    "    lines_of_text=[]\n",
    "    print(\"P Test Commencing\\n\")\n",
    "    for i in range(0,featuresLen):\n",
    "        droppedColumn=keyList[i]\n",
    "        df=df.drop(columns=[str(droppedColumn)])\n",
    "        X = pd.DataFrame(df.iloc[:,:-1])\n",
    "        X = (X - X.mean()) / (X.max() - X.min())\n",
    "        y = pd.DataFrame(df.iloc[:,-1])\n",
    "        \n",
    "        sc_x = StandardScaler()\n",
    "        sc_y = StandardScaler()\n",
    "        # Scale x and y (two scale objects)\n",
    "        X = sc_x.fit_transform(X)\n",
    "        y = sc_y.fit_transform(y)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "        ### convert one hot to numbers\n",
    "        y_true=y_test\n",
    "        maxAccuracy=1\n",
    "        lineString=\"\"\n",
    "        for j in range(1,100):#change range\n",
    "            for t in range(1,100):\n",
    "                alpha1=j*0.001\n",
    "                l1=t*0.01\n",
    "                clf =linear_model.ElasticNet(alpha=alpha1, l1_ratio=l1, max_iter=10000, positive=False, precompute=False, random_state=0, selection='cyclic', tol=0.0001, warm_start=False)\n",
    "                clf.fit(X_train, y_train)\n",
    "                y_pred = clf.predict(X_test)\n",
    "                accuracy=metrics.r2_score(y_true, y_pred)\n",
    "                if(accuracy<maxAccuracy):\n",
    "                    maxAccuracy=accuracy\n",
    "                    lineString=\"DroppedColumn:\"+droppedColumn+\" Alpha:\"+str(alpha1)+\" L1 ratio:\"+str(l1) +\" Test:P MSE:\"+str(accuracy)+\"\\n\"\n",
    "                \n",
    "        print(lineString)\n",
    "        file.write(lineString)\n",
    "\n",
    "    file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeuralNet(classCount,csvName,command,layerCount):\n",
    "    hlayer = list()\n",
    "    alphalist = [1e-3, 1e-5, 1e-8, 1e-10] #you can change alpha parameters\n",
    "    file = open(csvName+'_NeuralNet_'+command+'_C_'+str(classCount)+'_L_'+str(layerCount)+'.txt')\n",
    "    \n",
    "    df2 = pd.read_csv(csvName)\n",
    "    df2 = df2.dropna()\n",
    "    df2=df2.reset_index(drop=True)\n",
    "    df=makeClassDataFrame(df2,classCount,command)\n",
    "    dd=FeatureSelection(df)\n",
    "    keyList=list(dd.keys())\n",
    "    lines_of_text=[]\n",
    "    print(\"ClassCount=\"+str(classCount)+\"\\n\")\n",
    "    lines_of_text.append(\"ClassCount=\"+str(classCount)+\"\\n\")\n",
    "    \n",
    "    \n",
    "    if(layerCount==2):\n",
    "        for i in range(1,11):\n",
    "            for j in range(1,11): \n",
    "                tup = (random.randint(1,21)*25,random.randint(1,21)*5)           \n",
    "                hlayer.append(tup)\n",
    "  \n",
    "    \n",
    "    if(layerCount==3):\n",
    "        for i in range(1,11):\n",
    "            for j in range(1,11): \n",
    "                tup = (random.randint(1,21)*25,random.randint(1,21)*5,random.randint(1,21)*5)           \n",
    "                hlayer.append(tup)\n",
    "    \n",
    "    if(layerCount==4):\n",
    "        for i in range(1,11):\n",
    "            for j in range(1,11): \n",
    "                tup = (random.randint(1,21)*25,random.randint(1,21)*5,random.randint(1,21)*5,random.randint(1,21)*25)           \n",
    "                hlayer.append(tup)      \n",
    "    \n",
    "    if(layerCount==5):\n",
    "        for i in range(1,11):\n",
    "            for j in range(1,11): \n",
    "                tup = (random.randint(1,21)*25,random.randint(1,21)*5,random.randint(1,21)*5,random.randint(1,21)*25,random.randint(1,21)*25)           \n",
    "                hlayer.append(tup)\n",
    "    \n",
    "    else:\n",
    "        print(\"Please enter a valid layer count\")\n",
    "        return\n",
    "        \n",
    "    X = pd.DataFrame(df.iloc[:,:-1])\n",
    "    X = (X - X.mean()) / (X.max() - X.min())\n",
    "    y = pd.DataFrame(df.iloc[:,-1])\n",
    "    y = pd.get_dummies(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "    ### convert one hot to numbers\n",
    "    y_train = np.argmax(y_train.values, axis=-1)\n",
    "    y_true = np.argmax(y_test.values, axis=-1)\n",
    "    maxAccuracy=0\n",
    "    lineString=\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for j in range(0,len(hlayer)):#change range\n",
    "            for i in range(0, len(alphalist)):\n",
    "                clf = MLPClassifier(solver='lbfgs', alpha=alphalist[i], hidden_layer_sizes=hlayer[j], random_state=1)\n",
    "                clf.fit(X_train.values, y_train)\n",
    "                y_pred = clf.predict(X_test.values)\n",
    "                accuracy=accuracy_score(y_true, y_pred)\n",
    "                if(accuracy>maxAccuracy):\n",
    "                    maxAccuracy=accuracy\n",
    "                    \n",
    "                    lineString=\"DroppedColumn:NoDroppedColumn HH:\" +str(hlayer[j]) + \" Alpha:\" + str(alphalist[i])+\" Accuracy:\"+str(accuracy)+\"\\n\"\n",
    "    \n",
    "    \n",
    "    print(lineString)\n",
    "    file.write(lineString)\n",
    "    print(\"ClassCount:\"+ str(classCount)+ \" Finished: NoDroppedColumn\")\n",
    "    \n",
    "    for i in range(0,22):\n",
    "        droppedColumn=keyList[i]\n",
    "        df=df.drop(columns=[str(droppedColumn)])\n",
    "        X = pd.DataFrame(df.iloc[:,:-1])\n",
    "        X = (X - X.mean()) / (X.max() - X.min())\n",
    "        y = pd.DataFrame(df.iloc[:,-1])\n",
    "        y = pd.get_dummies(y)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "        ### convert one hot to numbers\n",
    "        y_train = np.argmax(y_train.values, axis=-1)\n",
    "\n",
    "        y_true = np.argmax(y_test.values, axis=-1)\n",
    "        maxAccuracy=0\n",
    "        lineString=\"\"\n",
    "        \n",
    "        for j in range(0,len(hlayer)):#change range\n",
    "            for i in range(0, len(alphalist)):\n",
    "                clf = MLPClassifier(solver='lbfgs', alpha=alphalist[i], hidden_layer_sizes=hlayer[j], random_state=1)\n",
    "                clf.fit(X_train.values, y_train)\n",
    "                y_pred = clf.predict(X_test.values)\n",
    "                accuracy=accuracy_score(y_true, y_pred)\n",
    "                if(accuracy>maxAccuracy):\n",
    "                    maxAccuracy=accuracy\n",
    "                    lineString=\"DroppedColumn:\"+droppedColumn+\" HH:\" +str(hlayer[j]) + \" Alpha:\" + str(alphalist[i])+\" Accuracy:\"+str(accuracy)+\"\\n\"\n",
    "\n",
    "\n",
    "        print(lineString)\n",
    "        file.write(lineString)\n",
    "        print(\"ClassCount:\"+ str(classCount)+ \" Finished:\"+droppedColumn)\n",
    "\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def heatMap(csvName):\n",
    "    df = pd.read_csv(csvName)\n",
    "    df=df.dropna()\n",
    "    sns.heatmap(df.corr(), annot=True, fmt=\".2f\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def printDataHistograms(csvName):\n",
    "    df = pd.read_csv(csvName)\n",
    "    df=df.dropna()\n",
    "    for column in df.columns:\n",
    "        ax=sns.distplot(df[column])\n",
    "        plt.pause(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot_with_correlation_line(x, y, graph_filepath):\n",
    "    '''\n",
    "    http://stackoverflow.com/a/34571821/395857\n",
    "    x does not have to be ordered.\n",
    "    '''\n",
    "    # Scatter plot\n",
    "    plt.scatter(x, y)\n",
    "\n",
    "    # Add correlation line\n",
    "    axes = plt.gca()\n",
    "    m, b = np.polyfit(x, y, 1)\n",
    "    X_plot = np.linspace(axes.get_xlim()[0],axes.get_xlim()[1],100)\n",
    "    plt.plot(X_plot, m*X_plot + b, '-')\n",
    "\n",
    "    # Save figure\n",
    "    plt.savefig(graph_filepath, dpi=300, format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_m(y, x):\n",
    "    ones = np.ones(len(x[0]))\n",
    "    X = sm.add_constant(np.column_stack((x[0], ones)))\n",
    "    for ele in x[1:]:\n",
    "        X = sm.add_constant(np.column_stack((ele, X)))\n",
    "    results = sm.OLS(y, X).fit()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ElasticExperiment(csvName):\n",
    "\n",
    "    df2 = pd.read_csv(csvName)\n",
    "    df2=df2.dropna()\n",
    "    df2=df2.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "    X = pd.DataFrame(df2.iloc[:,:-1])\n",
    "    y = pd.DataFrame(df2.iloc[:,-1])\n",
    "\n",
    "\n",
    "    sc_x = StandardScaler()\n",
    "    sc_y = StandardScaler()\n",
    "    # Scale x and y (two scale objects)\n",
    "    X = sc_x.fit_transform(X)\n",
    "    y = sc_y.fit_transform(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "            ### convert one hot to numbers\n",
    "    y_true=y_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\"clf = AdaBoostClassifier(n_estimators=100)\n",
    "    clf.fit(X_train.values, y_train)\n",
    "    y_pred = clf.predict(X_test.values)\n",
    "    accuracy=accuracy_score(y_true, y_pred)\"\"\"\n",
    "\n",
    "    clf = linear_model.ElasticNet(alpha=0.001, l1_ratio=0.01,\n",
    "          max_iter=100000, positive=False, precompute=False,\n",
    "          random_state=0, selection='cyclic', tol=0.0001, warm_start=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy=metrics.r2_score(y_true, y_pred)\n",
    "\n",
    "    print(accuracy)\n",
    "    axis.sort()\n",
    "    plt.scatter(axis,y_test,  color='black')\n",
    "    plt.scatter(axis,y_pred,  color='blue')\n",
    "\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(0,len(axis)):\n",
    "        plt.plot([axis[i],axis[i]], [y_pred[i],y_test[i]], 'r-')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveConfusionMatricesNeuralNet(csvName, path,command,classCount,layerCount):\n",
    "    \n",
    "    classes = [['A', 'B'],['A', 'B', 'C'], ['A', 'B', 'C', 'D'],['A', 'B', 'C', 'D','E'],['A', 'B', 'C', 'D','E','F']]\n",
    "    files=[]\n",
    "    for i in range(classCount[0],classCount[1]+1):\n",
    "        files.append(path+'/'+csvName+'_NeuralNet_'+command+'_C_'+str(i)+'_L_'+str(layerCount)+'.txt')\n",
    "    for i in range(len(files)):\n",
    "        acc_list = list()\n",
    "        metric_list = list()\n",
    "        hiddenlayer_list = list()\n",
    "        alphaList=list()\n",
    "        class_val = files[i][len(files[i])-5]\n",
    "        print(class_val)\n",
    "        with open(files[i]) as file:\n",
    "            for line in file: \n",
    "                if not line.strip(): continue\n",
    "                h_list=list()\n",
    "                colIndex1=line.find(':')+1\n",
    "                colIndex2=line.find(\"HH\")-1\n",
    "                droppedColumn=line[colIndex1:colIndex2]\n",
    "                \n",
    "                hlayerIndex1=line.find(':',colIndex2)+1\n",
    "                hlayerIndex2=line.find(')',hlayerIndex1)\n",
    "                h_layer=line[hlayerIndex1+1:hlayerIndex2]\n",
    "                h_layer=str(h_layer)\n",
    "                h_layer=h_layer.replace(\",\",\"\")\n",
    "                h_layer=h_layer.split()\n",
    "                real=()\n",
    "                \n",
    "                \n",
    "                for b in range(0,int(layerCount)):\n",
    "                    real=real+(int(h_layer[b]),)\n",
    "                \n",
    "                \n",
    "                \n",
    "                print(real)\n",
    "                AlphaIndex1=line.find(':',hlayerIndex2)+1\n",
    "                AlphaIndex2=line.find(' ',AlphaIndex1)\n",
    "                alpha=float(line[AlphaIndex1:AlphaIndex2])\n",
    "                \n",
    "                \n",
    "                \n",
    "                AccIndex1=line.find(':',AlphaIndex2)+1\n",
    "                AccIndex2=line.find(' ',line.find('\\n'))\n",
    "                accuracy=float(line[AccIndex1:AccIndex2])\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                alphaList.append(alpha)\n",
    "                hiddenlayer_list.append(real)\n",
    "                \n",
    "                \n",
    "                \n",
    "                metric_list.append(droppedColumn)\n",
    "                acc_list.append(accuracy)\n",
    "        #print(acc_list)  \n",
    "       # print(metric_list)\n",
    "        max_acc = max(acc_list)\n",
    "        index = acc_list.index(max_acc)\n",
    "        print(metric_list)\n",
    "        #print(hiddenlayer_list[index])\n",
    "\n",
    "        plt.barh(np.arange(len(metric_list)), acc_list)\n",
    "        plt.yticks(np.arange(len(metric_list)), metric_list)\n",
    "        plt.xlabel('Accuracy')\n",
    "        plt.title('Neural Net ' + str(class_val)+ ' Classes '+str(layerCount)+' Hidden Layer')\n",
    "        plt.savefig(csvName+'_NeuralNet_AccStack_C_'+str(class_val)+'_L_'+layerCount+'.png')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        df2 = pd.read_csv(csvName)\n",
    "        df2 = df2.dropna()\n",
    "        df2=df2.reset_index(drop=True)\n",
    "        df=makeClassDataFrame(df2,int(class_val),\"equallySliced\")\n",
    "        i_class_val = int(class_val)\n",
    "\n",
    "\n",
    "        for i in range(0,index+1):\n",
    "            if(metric_list[i]!=\"NoDroppedColumn\"):\n",
    "                df=df.drop(columns=metric_list[i])\n",
    "            X = pd.DataFrame(df.iloc[:,:-1])\n",
    "            X = (X - X.mean()) / (X.max() - X.min())\n",
    "            y = pd.DataFrame(df.iloc[:,-1])\n",
    "            y = pd.get_dummies(y)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "                ### convert one hot to numbers\n",
    "            y_train = np.argmax(y_train.values, axis=-1)\n",
    "\n",
    "            y_true = np.argmax(y_test.values, axis=-1)\n",
    "\n",
    "\n",
    "            clf = MLPClassifier(solver='lbfgs', alpha=alphaList[i], hidden_layer_sizes=(hiddenlayer_list[i]), random_state=1)\n",
    "            clf.fit(X_train.values, y_train)\n",
    "            y_pred = clf.predict(X_test.values)\n",
    "            accuracy=accuracy_score(y_true, y_pred)\n",
    "\n",
    "            print(accuracy)\n",
    "\n",
    "            cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "            cmap = plt.get_cmap('Blues')\n",
    "            cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.imshow(cnf_matrix, interpolation='nearest', cmap=cmap)\n",
    "            print(cnf_matrix)\n",
    "            tick_marks = np.arange(len(classes[i_class_val-2]))\n",
    "            plt.xticks(tick_marks, classes[i_class_val-2])\n",
    "            plt.yticks(tick_marks, classes[i_class_val-2])\n",
    "            #plt.matshow(cnf_matrix)\n",
    "            plt.title('Confusion matrix for class size ' + str(class_val) + ' HiddenLayer = ' + str(hiddenlayer_list[i]) +' LR: ' + str(alphaList[i]))\n",
    "            thresh = cnf_matrix.max() / 2\n",
    "            for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "                    plt.text(j, i, format(cnf_matrix[i, j]),\n",
    "                             horizontalalignment=\"center\",\n",
    "                             color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
    "            plt.colorbar()\n",
    "            plt.ylabel('True label')\n",
    "            plt.xlabel('Predicted label')\n",
    "            \n",
    "            plt.savefig(csvName+'_NeuralNet_CM_C_'+str(class_val)+'_L_'+str(layerCount)+'.png')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveConfusionMatricesTrees(csvName,path,treeMethodName,command,classCount):\n",
    "    classes = [['A', 'B'],['A', 'B', 'C'], ['A', 'B', 'C', 'D'],['A', 'B', 'C', 'D','E'],['A', 'B', 'C', 'D','E','F']]\n",
    "\n",
    "    files=[]\n",
    "    for i in range(classCount[0],classCount[1]+1):\n",
    "        files.append(path+'/'+csvName+'_'+treeMethodName+'_'+command+'_C_'+str(i)+'.txt')\n",
    "    for i in range(len(files)):\n",
    "        acc_list = list()\n",
    "        metric_list = list()\n",
    "        hiddenlayer_list = list()\n",
    "        est_list = list()\n",
    "        filename_split = files[i].split(\"/\")\n",
    "        class_val = filename_split[1][14:15]\n",
    "        with open(files[i]) as file:\n",
    "\n",
    "            for line in file: \n",
    "                if not line.strip(): continue       \n",
    "                line = line.replace('\\n','')\n",
    "                splitted = line.split(\":\") \n",
    "                est = splitted[2]\n",
    "                est2 = est.replace('Accuracy','')\n",
    "                estimator = est2.strip()\n",
    "                est_list.append(estimator)\n",
    "                split_val = splitted[1].replace('Estimator', '')\n",
    "                split_val2 = split_val.strip()\n",
    "                metric_list.append(split_val2)\n",
    "                acc_list.append(float(splitted[3])*100)\n",
    "        #print(acc_list)  \n",
    "        #print(metric_list)\n",
    "        #print(est_list)\n",
    "        max_acc = max(acc_list)\n",
    "        print(max_acc)\n",
    "        index = acc_list.index(max_acc)\n",
    "        print(metric_list[index])\n",
    "        print(est_list[index])\n",
    "\n",
    "        plt.barh(np.arange(len(metric_list)), acc_list)\n",
    "        plt.yticks(np.arange(len(metric_list)), metric_list)\n",
    "        plt.xlabel('Accuracy')\n",
    "        plt.title(threeMethodName+' '+ str(class_val) + ' Classes')\n",
    "        \n",
    "        plt.savefig(csvName+'_'+treeMethodName+'_AccStack_C'+str(class_val)+'.png')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        df2 = pd.read_csv(csvName)\n",
    "        df2 = df2.dropna()\n",
    "        df2=df2.reset_index(drop=True)\n",
    "        df=makeClassDataFrame(df2,int(class_val),command)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(0,index+1):\n",
    "\n",
    "            df=df.drop(columns=metric_list[i])\n",
    "            X = pd.DataFrame(df.iloc[:,:-1])\n",
    "            X = (X - X.mean()) / (X.max() - X.min())\n",
    "            y = pd.DataFrame(df.iloc[:,-1])\n",
    "            y = pd.get_dummies(y)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "            ### convert one hot to numbers\n",
    "            y_train = np.argmax(y_train.values, axis=-1)\n",
    "\n",
    "            y_true = np.argmax(y_test.values, axis=-1)\n",
    "\n",
    "\n",
    "        clf = TreeMethod(n_estimators=estimator)\n",
    "        clf.fit(X_train.values, y_train)\n",
    "        y_pred = clf.predict(X_test.values)\n",
    "        accuracy=accuracy_score(y_true, y_pred)\n",
    "\n",
    "        print(accuracy)\n",
    "\n",
    "        cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "        cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(cnf_matrix, interpolation='nearest', cmap=cmap)\n",
    "        print(cnf_matrix)\n",
    "        tick_marks = np.arange(len(classes[int(class_val)-2]))\n",
    "        plt.xticks(tick_marks, classes[int(class_val)-2])\n",
    "        plt.yticks(tick_marks, classes[int(class_val)-2])\n",
    "        #plt.matshow(cnf_matrix)\n",
    "        plt.title('Confusion matrix for '+treeMethodName+' class size ' + str(class_val) +  ' Estimator ' + str(est_list[index]))\n",
    "        thresh = cnf_matrix.max() / 2\n",
    "        for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "                plt.text(j, i, format(cnf_matrix[i, j]),\n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
    "        plt.colorbar()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.savefig(csvName+'_'+treeMethodName+'_CM_C_'+str(class_val)+'.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveConfusionMatricesSVM(csvName,path,command,classCount):\n",
    "    classes = [['A', 'B'],['A', 'B', 'C'], ['A', 'B', 'C', 'D'],['A', 'B', 'C', 'D','E'],['A', 'B', 'C', 'D','E','F']]\n",
    "    \n",
    "    \n",
    "    files=[]\n",
    "    for i in range(classCount[0],classCount[1]+1):\n",
    "        files.append(path+'/'+csvName+'_SVM_'+command+'_C_'+str(i)+'.txt')\n",
    "    classes = [['A', 'B'],['A', 'B', 'C'], ['A', 'B', 'C', 'D'],['A', 'B', 'C', 'D','E'],['A', 'B', 'C', 'D','E','F']]\n",
    "\n",
    "    for i in range(len(files)):\n",
    "        acc_list = list()\n",
    "        metric_list = list()\n",
    "        hiddenlayer_list = list()\n",
    "        est_list = list()\n",
    "        filename_split = files[i].split(\"/\")\n",
    "        class_val = filename_split[1][3:4]\n",
    "        print(class_val)\n",
    "        with open(files[i]) as file:\n",
    "\n",
    "\n",
    "            for line in file: \n",
    "                if not line.strip(): continue       \n",
    "                line = line.replace('\\n','')\n",
    "                splitted = line.split(\":\") \n",
    "                est = splitted[2]\n",
    "                est2 = est.replace('Accuracy','')\n",
    "                estimator = est2.strip()\n",
    "                est_list.append(estimator)\n",
    "                split_val = splitted[1][:-1]\n",
    "                split_val2 = split_val.strip()\n",
    "                metric_list.append(split_val2)\n",
    "                acc_list.append(float(splitted[3])*100)\n",
    "        #print(acc_list)  \n",
    "        #print(metric_list)\n",
    "        #print(est_list)\n",
    "        max_acc = max(acc_list)\n",
    "        print(max_acc)\n",
    "        index = acc_list.index(max_acc)\n",
    "        print(metric_list[index])\n",
    "        print(est_list[index])\n",
    "\n",
    "        plt.barh(np.arange(len(metric_list)), acc_list)\n",
    "        plt.yticks(np.arange(len(metric_list)), metric_list)\n",
    "        plt.xlabel('Accuracy')\n",
    "        plt.title('SVM ' + str(class_val) + ' Classes')\n",
    "        plt.savefig(csvName+'_SVM_AccStack_C'+str(class_val)+'.png')\n",
    "        plt.show()\n",
    "\n",
    "        df2 = pd.read_csv(csvName)\n",
    "        df2 = df2.dropna()\n",
    "        df2=df2.reset_index(drop=True)\n",
    "        df=makeClassDataFrame(df2,int(class_val),command)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(0,index+1):\n",
    "\n",
    "            df=df.drop(columns=metric_list[i])\n",
    "            X = pd.DataFrame(df.iloc[:,:-1])\n",
    "            X = (X - X.mean()) / (X.max() - X.min())\n",
    "            y = pd.DataFrame(df.iloc[:,-1])\n",
    "            y = pd.get_dummies(y)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "            ### convert one hot to numbers\n",
    "            y_train = np.argmax(y_train.values, axis=-1)\n",
    "\n",
    "            y_true = np.argmax(y_test.values, axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "        clf = SVC(C = float(est_list[index]), kernel='rbf', degree=3, )\n",
    "        clf.fit(X_train.values, y_train)\n",
    "        clf.fit(X_train.values, y_train)\n",
    "\n",
    "        y_pred = clf.predict(X_test.values)\n",
    "        accuracy=accuracy_score(y_true, y_pred)\n",
    "\n",
    "        print(accuracy)\n",
    "\n",
    "        cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "        cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(cnf_matrix, interpolation='nearest', cmap=cmap)\n",
    "        print(cnf_matrix)\n",
    "        tick_marks = np.arange(len(classes[int(class_val)-2]))\n",
    "        plt.xticks(tick_marks, classes[int(class_val)-2])\n",
    "        plt.yticks(tick_marks, classes[int(class_val)-2])\n",
    "        #plt.matshow(cnf_matrix)\n",
    "        plt.title('Confusion matrix for SVM class size:' +  str(class_val) +  ' C_val:'  + str(est_list[index])+' Accuracy:'+str(accuracy))\n",
    "        thresh = cnf_matrix.max() / 2\n",
    "        for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "                plt.text(j, i, format(cnf_matrix[i, j]),\n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
    "        plt.colorbar()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.savefig(csvName+'_SVM_CM_C_'+str(class_val)+'.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your target value must be always at the end, and must be called percentage, you can change default name in the function\n",
    "csvName=\"chart_closure_lang_time_cyclomatic.csv\"\n",
    "\n",
    "#distribute your classes according to your command (useEquallySliced for default)\n",
    "command1=\"equallySliced\"\n",
    "command2=\"betweenEqual\"\n",
    "\n",
    "#look heatmap to see correlated features and print histograms of each data\n",
    "heatMap(csvName)\n",
    "printDataHistograms(csvName)\n",
    "\n",
    "#tree classifier names\n",
    "adaboost=\"AdaBoost\"\n",
    "extratrees=\"ExtraTrees\"\n",
    "\n",
    "classSizeRange1=2\n",
    "classSizeRange2=6\n",
    "layerCount=2\n",
    "for i in range(classSizeRange1,classSizeRange2+1):\n",
    "    print(\"Class:\"+str(i)+\"\\n\")\n",
    "    #AdaBoost(i,csvName,command1)\n",
    "    #TreeClassifier(i,csvName,command1,adaboost)\n",
    "    #TreeClassifier(i,csvName,command1,extratrees)\n",
    "    #SVM(i,csvName,command1)\n",
    "    #NeuralNet(i,csvName,layerCount)\n",
    "Elastic(csvName)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Generator Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "classSizeRange1=2\n",
    "classSizeRange2=6\n",
    "classCountRange = [None] * 2\n",
    "#range of  your class counts for instance if you have text files for 2, 3 and 4 classes please\n",
    "#initiliaze classSizeRange1=2 and classSizeRange2=4\n",
    "\n",
    "classCountRange[0]=classSizeRange1\n",
    "classCountRange[1]=classSizeRange2\n",
    "#change the path according to your folders\n",
    "defaultLayerPath=os.getcwd()\n",
    "\n",
    "saveConfusionMatricesTrees(csvName,path,treeMethodName,command,classCountRange):\n",
    "saveConfusionMatricesNeuralNet(csvName, defaultLayerPath,command1,classCountRange,layerCount)\n",
    "saveConfusionMatricesSVM(csvName,path,command,classCountRange):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
